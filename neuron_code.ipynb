{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c81f2e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3\n"
     ]
    }
   ],
   "source": [
    "i=[1,2,3]\n",
    "w=[0.2,0.8,-0.5]\n",
    "bias=2\n",
    "\n",
    "output=i[0]*w[0]+ i[1]*w[1]+ i[2]*w[2] + bias\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "680f2cd0",
   "metadata": {},
   "source": [
    "inputs can be from the different sensors or maybe ~from the previous layer's neurons~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f74e8ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.8\n"
     ]
    }
   ],
   "source": [
    "i=[1,2,3,2.5]\n",
    "w=[0.2,0.8,-0.5,1]\n",
    "bias=2\n",
    "output=i[0]*w[0]+ i[1]*w[1]+ i[2]*w[2] + i[3]*w[3] + bias\n",
    "print(output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "720bb095",
   "metadata": {},
   "source": [
    "modelling 3 neurons with 4 inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2700851a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.8, 1.21, 2.385]\n"
     ]
    }
   ],
   "source": [
    "i=[1,2,3,2.5]\n",
    "w_e=[0.2,0.8,-0.5,1]\n",
    "w_f=[0.5,-0.91,0.26,-0.5]\n",
    "w_g=[-0.26,-0.27,0.17,0.87]\n",
    "b_e=2\n",
    "b_f=3\n",
    "b_g=0.5\n",
    "output=[i[0]*w_e[0]+ i[1]*w_e[1]+ i[2]*w_e[2] + i[3]*w_e[3] + b_e,\n",
    "        i[0]*w_f[0]+ i[1]*w_f[1] + i[2]* w_f[2]+ i[3]* w_f[3]+ b_f,\n",
    "        i[0]*w_g[0]+ i[1]*w_g[1] + i[2]* w_g[2]+ i[3]* w_g[3]+ b_g\n",
    "]\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27a7e9b7",
   "metadata": {},
   "source": [
    "rather we use dot product(numpy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a9420a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.8   1.21  2.385]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "i=[1,2,3,2.5]\n",
    "\n",
    "w=[[0.2,0.8,-0.5,1],\n",
    "    [0.5,-0.91,0.26,-0.5],\n",
    "    [-0.26,-0.27,0.17,0.87]]\n",
    "b=[2,3,0.5]\n",
    "\n",
    "output=np.dot(w,i)+b\n",
    "\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae1d431",
   "metadata": {},
   "source": [
    "with batches of input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2bc9c195",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 4.8    1.21   2.385]\n",
      " [ 8.9   -1.81   0.2  ]\n",
      " [ 1.41   1.051  0.026]]\n"
     ]
    }
   ],
   "source": [
    "inputs=[[1,2,3,2.5],\n",
    "        [2,5,-1,2],\n",
    "        [-1.5,2.7,3.3,-0.8]]\n",
    "weights=[[0.2,0.8,-0.5,1],\n",
    "          [0.5,-0.91,0.26,-0.5],\n",
    "          [-0.26,-0.27,0.17,0.87]]\n",
    "biases=[2,3,0.5]\n",
    "output=np.dot(inputs,np.array(weights).T)+biases\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82fc1896",
   "metadata": {},
   "source": [
    "incoreect format(wt,input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a74a004d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 4.8    9.9   -0.09 ]\n",
      " [ 0.21  -1.81  -1.449]\n",
      " [ 3.885  2.7    0.026]]\n"
     ]
    }
   ],
   "source": [
    "inputs=[[1,2,3,2.5],\n",
    "        [2,5,-1,2],\n",
    "        [-1.5,2.7,3.3,-0.8]]\n",
    "weights=[[0.2,0.8,-0.5,1],\n",
    "          [0.5,-0.91,0.26,-0.5],\n",
    "          [-0.26,-0.27,0.17,0.87]]\n",
    "biases=[2,3,0.5]\n",
    "output=np.dot(weights,np.array(inputs).T)+biases\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad5d076e",
   "metadata": {},
   "source": [
    "add another layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "24ab6df1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The outout from 1st layer is:\n",
      " [[ 4.8    1.21   2.385]\n",
      " [ 8.9   -1.81   0.2  ]\n",
      " [ 1.41   1.051  0.026]]\n",
      "The outout from 2nd layer is:\n",
      " [[ 1.8    0.21   1.385]\n",
      " [ 5.9   -2.81  -0.8  ]\n",
      " [-1.59   0.051 -0.974]]\n"
     ]
    }
   ],
   "source": [
    "inputs=[[1,2,3,2.5],\n",
    "        [2,5,-1,2],\n",
    "        [-1.5,2.7,3.3,-0.8]]\n",
    "weights1=[[0.2,0.8,-0.5,1],\n",
    "          [0.5,-0.91,0.26,-0.5],\n",
    "          [-0.26,-0.27,0.17,0.87]]\n",
    "biases1=[2,3,0.5]\n",
    "weights2=[[0.1,-0.14,0.5],\n",
    "          [-0.5,0.12,-0.33],\n",
    "          [-0.44,0.73,-0.13]]\n",
    "biases2=[-1,2,-0.5]\n",
    "\n",
    "l1_output=np.dot(inputs,np.array(weights1).T)+biases1\n",
    "l2_output=np.dot(inputs,np.array(weights).T)+biases2\n",
    "print('The outout from 1st layer is:\\n',l1_output)\n",
    "print('The outout from 2nd layer is:\\n',l2_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "23206c3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.25529898  0.06536186]\n",
      " [ 0.08644362 -0.0742165 ]\n",
      " [ 0.22697546 -0.14543657]\n",
      " [ 0.00457585 -0.01871839]\n",
      " [ 0.15327792  0.14693588]]\n",
      "[[ 0.148296   -0.08397602]\n",
      " [ 0.14100315 -0.01340469]\n",
      " [ 0.20124979 -0.07290616]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "X=[[1,2,3,2.5],\n",
    "    [2,5,-1,2],\n",
    "    [-1.5,2.7,3.3,-0.8]]\n",
    "\n",
    "class Layer_Dense:\n",
    "    def __init__(self,n_inputs,n_neurons):\n",
    "        self.weights=0.10*np.random.randn(n_inputs,n_neurons)\n",
    "        self.biases=np.zeros((1,n_neurons))\n",
    "    def forward(self,inputs):\n",
    "\n",
    "        self.output=np.dot(inputs,self.weights)+ self.biases\n",
    "\n",
    "layer1=Layer_Dense(4,5)\n",
    "layer2=Layer_Dense(5,2)\n",
    "\n",
    "layer1.forward(X)\n",
    "\n",
    "# print(layer1.output)\n",
    "layer2.forward(layer1.output)\n",
    "print(layer2.weights)\n",
    "print(layer2.output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8592cda5",
   "metadata": {},
   "source": [
    "activation functions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "46ff4d83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00]\n",
      " [-8.35815910e-04 -7.90404272e-04 -1.33452227e-03  4.65504505e-04\n",
      "   4.56846210e-05]\n",
      " [-2.39994470e-03  5.93469958e-05 -2.24808278e-03  2.03573116e-04\n",
      "   6.10024377e-04]\n",
      " ...\n",
      " [ 1.13291524e-01 -1.89262271e-01 -2.06855070e-02  8.11079666e-02\n",
      "  -6.71350807e-02]\n",
      " [ 1.34588361e-01 -1.43197834e-01  3.09493970e-02  5.66337556e-02\n",
      "  -6.29687458e-02]\n",
      " [ 1.07817926e-01 -2.00809643e-01 -3.37579325e-02  8.72561932e-02\n",
      "  -6.81458861e-02]]\n",
      "[[0.00000000e+00 0.00000000e+00]\n",
      " [2.99555692e-03 9.64660756e-03]\n",
      " [1.28809698e-02 1.55628482e-02]\n",
      " [2.99747903e-02 4.44809627e-03]\n",
      " [3.93124595e-02 9.32828337e-03]\n",
      " [8.28829070e-04 5.04982509e-02]\n",
      " [5.34835160e-02 2.85062827e-02]\n",
      " [4.17361967e-02 5.70752136e-02]\n",
      " [5.54633923e-02 5.87686822e-02]\n",
      " [8.16038325e-02 4.00659069e-02]\n",
      " [8.91875103e-02 4.74197045e-02]\n",
      " [1.07160836e-01 0.00000000e+00]\n",
      " [1.21183202e-01 0.00000000e+00]\n",
      " [1.28777727e-01 2.56794747e-02]\n",
      " [1.41112968e-01 0.00000000e+00]\n",
      " [1.50579467e-01 0.00000000e+00]\n",
      " [1.13476366e-01 0.00000000e+00]\n",
      " [1.71552509e-01 0.00000000e+00]\n",
      " [1.67186841e-01 0.00000000e+00]\n",
      " [1.91325873e-01 1.50793232e-02]\n",
      " [1.36771902e-01 1.48679554e-01]\n",
      " [1.35606423e-01 0.00000000e+00]\n",
      " [1.04024746e-01 0.00000000e+00]\n",
      " [2.15633541e-01 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00]\n",
      " [2.46031418e-01 0.00000000e+00]\n",
      " [1.24166250e-01 0.00000000e+00]\n",
      " [1.32641941e-01 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00]\n",
      " [1.02452915e-02 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00]\n",
      " [1.11795291e-01 0.00000000e+00]\n",
      " [2.38806710e-01 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 2.47549772e-01]\n",
      " [0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 1.95242479e-01]\n",
      " [0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 6.45234585e-02]\n",
      " [0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 3.04570675e-01]\n",
      " [0.00000000e+00 1.47544429e-01]\n",
      " [0.00000000e+00 2.72004325e-02]\n",
      " [0.00000000e+00 3.62960041e-01]\n",
      " [0.00000000e+00 4.83915746e-01]\n",
      " [0.00000000e+00 4.68966633e-01]\n",
      " [0.00000000e+00 5.35878778e-01]\n",
      " [0.00000000e+00 4.31942016e-01]\n",
      " [0.00000000e+00 5.21580160e-01]\n",
      " [0.00000000e+00 5.13870835e-01]\n",
      " [0.00000000e+00 5.88396072e-01]\n",
      " [0.00000000e+00 5.69997609e-01]\n",
      " [0.00000000e+00 4.51193869e-01]\n",
      " [1.72540992e-01 6.23013735e-01]\n",
      " [5.35037480e-02 6.54381990e-01]\n",
      " [0.00000000e+00 6.05526745e-01]\n",
      " [4.44151521e-01 5.10630906e-01]\n",
      " [9.03030708e-02 6.80906713e-01]\n",
      " [4.55620110e-01 5.27424932e-01]\n",
      " [6.45984292e-01 2.87494838e-01]\n",
      " [5.84617138e-01 4.15401071e-01]\n",
      " [7.27224171e-01 8.40271171e-03]\n",
      " [3.36008549e-01 6.56367481e-01]\n",
      " [7.35656083e-01 1.32395625e-01]\n",
      " [6.16297543e-01 4.40565974e-01]\n",
      " [6.28073633e-01 4.41419423e-01]\n",
      " [7.26366043e-01 2.78083950e-01]\n",
      " [7.81131148e-01 1.02893755e-01]\n",
      " [7.88548410e-01 0.00000000e+00]\n",
      " [7.57483721e-01 2.81448126e-01]\n",
      " [5.82662702e-01 0.00000000e+00]\n",
      " [6.53483987e-01 0.00000000e+00]\n",
      " [8.14698577e-01 1.97872922e-01]\n",
      " [1.65076673e-01 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00]\n",
      " [1.28543124e-01 0.00000000e+00]\n",
      " [5.83978891e-01 0.00000000e+00]\n",
      " [7.80273199e-01 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00]\n",
      " [4.63849485e-01 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00]\n",
      " [2.57485043e-02 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 2.33798083e-02]\n",
      " [0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 5.64836562e-02]\n",
      " [0.00000000e+00 5.52896857e-02]\n",
      " [0.00000000e+00 8.20635408e-02]\n",
      " [0.00000000e+00 5.98242730e-02]\n",
      " [0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 1.25517607e-01]\n",
      " [0.00000000e+00 3.97006609e-02]\n",
      " [0.00000000e+00 1.20619588e-01]\n",
      " [0.00000000e+00 1.43606886e-01]\n",
      " [0.00000000e+00 1.03111513e-01]\n",
      " [0.00000000e+00 1.64411202e-01]\n",
      " [0.00000000e+00 1.88606262e-01]\n",
      " [0.00000000e+00 1.89215153e-01]\n",
      " [0.00000000e+00 1.15525723e-01]\n",
      " [0.00000000e+00 2.18009338e-01]\n",
      " [9.47438180e-02 2.12126598e-01]\n",
      " [0.00000000e+00 2.13965908e-01]\n",
      " [0.00000000e+00 2.50830054e-01]\n",
      " [0.00000000e+00 2.59368002e-01]\n",
      " [2.41241619e-01 1.27211019e-01]\n",
      " [1.59243613e-01 2.33737692e-01]\n",
      " [1.57247782e-01 2.47145116e-01]\n",
      " [2.39067562e-02 3.02085787e-01]\n",
      " [2.32032150e-01 2.10267216e-01]\n",
      " [1.04369961e-01 3.05918366e-01]\n",
      " [2.35107496e-01 2.36295521e-01]\n",
      " [1.79523319e-01 2.92777270e-01]\n",
      " [3.41323912e-01 9.21153203e-02]\n",
      " [3.55456382e-01 7.66952783e-02]\n",
      " [3.27276438e-01 1.80470958e-01]\n",
      " [3.81890804e-01 3.86176892e-02]\n",
      " [2.89765954e-01 2.66878128e-01]\n",
      " [2.68961608e-01 3.01510036e-01]\n",
      " [4.03800040e-01 0.00000000e+00]\n",
      " [4.16720092e-01 0.00000000e+00]\n",
      " [3.76112401e-01 0.00000000e+00]\n",
      " [3.19485776e-02 0.00000000e+00]\n",
      " [2.89429367e-01 0.00000000e+00]\n",
      " [4.63996798e-01 0.00000000e+00]\n",
      " [1.85740978e-01 0.00000000e+00]\n",
      " [4.84158278e-01 0.00000000e+00]\n",
      " [4.13589716e-01 0.00000000e+00]\n",
      " [3.22098076e-01 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00]\n",
      " [3.86825025e-01 0.00000000e+00]\n",
      " [3.71773154e-01 0.00000000e+00]\n",
      " [1.62570089e-01 0.00000000e+00]\n",
      " [2.58585244e-01 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00]\n",
      " [2.71145850e-01 0.00000000e+00]\n",
      " [2.40553409e-01 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 1.25632852e-01]\n",
      " [0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 1.76559985e-01]\n",
      " [0.00000000e+00 3.75063084e-02]\n",
      " [0.00000000e+00 2.98134685e-01]\n",
      " [0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 4.51079965e-01]\n",
      " [0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 1.19491868e-01]\n",
      " [0.00000000e+00 2.86570013e-01]\n",
      " [0.00000000e+00 5.20015776e-01]\n",
      " [0.00000000e+00 4.72839653e-01]\n",
      " [0.00000000e+00 1.75022930e-01]\n",
      " [0.00000000e+00 5.22272348e-01]\n",
      " [0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 8.47333908e-01]\n",
      " [0.00000000e+00 4.16194111e-01]\n",
      " [0.00000000e+00 6.56008542e-01]\n",
      " [0.00000000e+00 8.78231227e-01]\n",
      " [0.00000000e+00 8.40797246e-01]\n",
      " [7.10775614e-01 5.50436974e-01]\n",
      " [0.00000000e+00 8.35520685e-01]\n",
      " [4.21108097e-01 8.17056775e-01]\n",
      " [3.82092923e-01 8.47107053e-01]\n",
      " [0.00000000e+00 9.38655138e-01]\n",
      " [7.47896850e-01 5.84970891e-01]\n",
      " [5.88822305e-01 7.57702231e-01]\n",
      " [9.14996028e-01 3.21083277e-01]\n",
      " [9.58145797e-01 2.04843029e-01]\n",
      " [8.38562548e-01 0.00000000e+00]\n",
      " [9.69426990e-01 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00]\n",
      " [9.14306752e-03 4.29356797e-03]\n",
      " [1.91021413e-02 0.00000000e+00]\n",
      " [2.96353418e-02 0.00000000e+00]\n",
      " [3.85543592e-02 0.00000000e+00]\n",
      " [3.78438421e-02 3.34455334e-02]\n",
      " [5.96956834e-02 0.00000000e+00]\n",
      " [7.04677626e-02 5.81241259e-03]\n",
      " [6.98159263e-02 0.00000000e+00]\n",
      " [8.22631791e-02 0.00000000e+00]\n",
      " [5.07112965e-02 0.00000000e+00]\n",
      " [7.33842030e-02 0.00000000e+00]\n",
      " [4.56192940e-02 0.00000000e+00]\n",
      " [1.03771001e-01 0.00000000e+00]\n",
      " [1.22611716e-01 0.00000000e+00]\n",
      " [9.53920186e-02 0.00000000e+00]\n",
      " [6.04712553e-02 0.00000000e+00]\n",
      " [1.44758979e-02 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00]\n",
      " [1.78390555e-02 0.00000000e+00]\n",
      " [8.76751468e-02 0.00000000e+00]\n",
      " [9.10300482e-03 0.00000000e+00]\n",
      " [1.60965777e-04 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00]\n",
      " [8.02290589e-02 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 1.25866413e-01]\n",
      " [0.00000000e+00 2.66282916e-01]\n",
      " [0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 1.80498064e-01]\n",
      " [0.00000000e+00 2.58542061e-01]\n",
      " [0.00000000e+00 6.42675310e-02]\n",
      " [0.00000000e+00 1.53933972e-01]\n",
      " [0.00000000e+00 2.44437188e-01]\n",
      " [0.00000000e+00 2.56800681e-01]\n",
      " [0.00000000e+00 2.95721233e-01]\n",
      " [0.00000000e+00 6.59067407e-02]\n",
      " [4.17104848e-02 4.62770551e-01]\n",
      " [7.30770975e-02 4.69089448e-01]\n",
      " [0.00000000e+00 3.73647630e-01]\n",
      " [0.00000000e+00 3.01243097e-01]\n",
      " [8.95722732e-02 4.97044086e-01]\n",
      " [0.00000000e+00 4.96608764e-01]\n",
      " [9.95909050e-02 5.15724599e-01]\n",
      " [3.27057391e-02 5.34353554e-01]\n",
      " [3.37681264e-01 4.28359687e-01]\n",
      " [3.86817127e-01 3.98766190e-01]\n",
      " [9.06921476e-02 5.58338881e-01]\n",
      " [0.00000000e+00 5.74471653e-01]\n",
      " [0.00000000e+00 5.84597528e-01]\n",
      " [5.39511859e-01 2.53169537e-01]\n",
      " [1.98358148e-01 5.72680950e-01]\n",
      " [4.31343615e-01 4.39997524e-01]\n",
      " [4.62868482e-01 4.21850264e-01]\n",
      " [5.94172835e-01 2.27853715e-01]\n",
      " [2.30009332e-01 6.04162455e-01]\n",
      " [6.55944824e-01 2.85461489e-02]\n",
      " [6.49851620e-01 0.00000000e+00]\n",
      " [6.72798991e-01 0.00000000e+00]\n",
      " [6.86836302e-01 0.00000000e+00]\n",
      " [6.62706614e-01 0.00000000e+00]\n",
      " [5.96542180e-01 0.00000000e+00]\n",
      " [4.35550809e-01 5.69763780e-01]\n",
      " [1.71986911e-02 0.00000000e+00]\n",
      " [4.78151858e-01 0.00000000e+00]\n",
      " [6.74676895e-01 0.00000000e+00]\n",
      " [5.90618432e-01 0.00000000e+00]\n",
      " [2.63736039e-01 0.00000000e+00]\n",
      " [4.09585685e-01 0.00000000e+00]\n",
      " [7.77826965e-01 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00]\n",
      " [1.98979661e-01 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00]\n",
      " [2.74292469e-01 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00]\n",
      " [9.54423249e-02 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 5.24532199e-01]\n",
      " [0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 3.01196396e-01]\n",
      " [0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 2.37015888e-01]\n",
      " [0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 3.33390683e-01]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import nnfs\n",
    "nnfs.init()\n",
    "from nnfs.datasets import spiral_data\n",
    "np.random.seed(0)\n",
    "# X=[[1,2,3,2.5],\n",
    "#     [2,5,-1,2],\n",
    "#     [-1.5,2.7,3.3,-0.8]]\n",
    "X,y=spiral_data(100,3)\n",
    "class Layer_Dense:\n",
    "    def __init__(self,n_inputs,n_neurons):\n",
    "        self.weights=0.10*np.random.randn(n_inputs,n_neurons)\n",
    "        self.biases=np.zeros((1,n_neurons))\n",
    "    def forward(self,inputs):\n",
    "        self.output=np.dot(inputs,self.weights)+ self.biases\n",
    "class Activation_ReLU:\n",
    "    def forward(self,inputs):\n",
    "        self.output=np.maximum(0,inputs)\n",
    "\n",
    "\n",
    "layer1=Layer_Dense(2,5)\n",
    "# acivation1=Activation_ReLU()\n",
    "layer1.forward(X)\n",
    "print(layer1.output)\n",
    "activation1=Activation_ReLU()\n",
    "activation1.forward(X)\n",
    "print(activation1.output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec266d0",
   "metadata": {},
   "source": [
    "softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a3574fa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[121.51041751873483, 3.353484652549023, 10.859062664920513]\n",
      "The normalised values are:  [0.8952826639572619, 0.024708306782099374, 0.0800090292606387]\n",
      "The summed value is:  0.9999999999999999\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "layer_outputs=[4.8,1.21,2.385]\n",
    "E=math.e\n",
    "exp_values=[]\n",
    "for output in layer_outputs:\n",
    "    exp_values.append(E**output)\n",
    "print(exp_values)\n",
    "\n",
    "norm_base=sum(exp_values)\n",
    "norm_values=[]\n",
    "for values in exp_values:\n",
    "    norm_values.append(values/norm_base)\n",
    "print('The normalised values are: ',norm_values)\n",
    "print('The summed value is: ',sum(norm_values))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f9c16d5",
   "metadata": {},
   "source": [
    "categorical cross-entropy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d0536bbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.35667494393873245\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "softmax_output=[0.7,0.1,0.2]\n",
    "target_class=[1,0,0]\n",
    "\n",
    "loss = 0\n",
    "for p, t in zip(softmax_output, target_class):\n",
    "    loss += -t * math.log(p)\n",
    "\n",
    "print(loss)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f7bd2134",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.35667494393873245\n",
      "0.35667494393873245\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "softmax_output=[0.7,0.1,0.2]\n",
    "target_output=[1,0,0]\n",
    "loss=-(math.log(softmax_output[0])*target_output[0]+\n",
    "       math.log(softmax_output[1])*target_output[1]+\n",
    "       math.log(softmax_output[2])*target_output[2]\n",
    "        )\n",
    "print(loss)\n",
    "loss1=-math.log(softmax_output[0])\n",
    "print(loss1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "139b4240",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7 0.5 0.9]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "softmax_output=np.array([[0.7,0.1,0.2],\n",
    "                        [0.1,0.5,0.4],\n",
    "                        [0.02,0.9,0.08]])\n",
    "class_targets=[0,1,1]\n",
    "print(softmax_output[[0,1,2],class_targets])  #prints out softmax_output ko 0,1,2 row ko [0,1,1](class targets)index ma vako values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "dda55cc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.35667494 0.69314718 0.10536052]\n",
      "1.1551826401565042\n"
     ]
    }
   ],
   "source": [
    "neg_log=-np.log(softmax_output[range(len(softmax_output)),class_targets])\n",
    "print(neg_log)\n",
    "print(sum(neg_log))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96937288",
   "metadata": {},
   "source": [
    "-log(0)= infinite so we have problem here sooo..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "6b4a4583",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.33333334 0.33333334 0.33333334]\n",
      " [0.33334148 0.33333018 0.33332834]\n",
      " [0.33335316 0.33332598 0.3333209 ]\n",
      " [0.333332   0.3333076  0.3333604 ]\n",
      " [0.33333603 0.33330086 0.33336315]]\n",
      "1.0988971\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import nnfs\n",
    "nnfs.init()\n",
    "from nnfs.datasets import spiral_data\n",
    "np.random.seed(0)\n",
    "\n",
    "X, y = spiral_data(100, 3)\n",
    "\n",
    "class Layer_Dense:\n",
    "    def __init__(self, n_inputs, n_neurons):\n",
    "        self.weights = 0.10 * np.random.randn(n_inputs, n_neurons)\n",
    "        self.biases = np.zeros((1, n_neurons))\n",
    "    def forward(self, inputs):\n",
    "        self.output = np.dot(inputs, self.weights) + self.biases\n",
    "\n",
    "class Activation_ReLU:\n",
    "    def forward(self, inputs):\n",
    "        self.output = np.maximum(0, inputs)\n",
    "\n",
    "class Activation_Softmax:\n",
    "    def forward(self, inputs):\n",
    "        exp_values = np.exp(inputs - np.max(inputs, axis=1, keepdims=True))\n",
    "        probabilities = exp_values / np.sum(exp_values, axis=1, keepdims=True)\n",
    "        self.output = probabilities\n",
    "\n",
    "class Loss:\n",
    "    def calculate(self, output, y):\n",
    "        sample_losses = self.forward(output, y)\n",
    "        data_loss = np.mean(sample_losses)\n",
    "        return data_loss\n",
    "\n",
    "class Loss_Categorical_Cross_entropy(Loss):\n",
    "    def forward(self, y_pred, y_true):\n",
    "        samples = len(y_pred)\n",
    "        y_pred_clipped = np.clip(y_pred, 1e-7, 1-1e-7)\n",
    "\n",
    "        # sparse labels\n",
    "        if len(y_true.shape) == 1:\n",
    "            correct_confidences = y_pred_clipped[range(samples), y_true]\n",
    "\n",
    "        # one-hot labels\n",
    "        elif len(y_true.shape) == 2:\n",
    "            correct_confidences = np.sum(y_pred_clipped * y_true, axis=1)\n",
    "\n",
    "        negative_log_likelihoods = -np.log(correct_confidences)\n",
    "        return negative_log_likelihoods\n",
    "\n",
    "# MODEL\n",
    "layer1 = Layer_Dense(2, 5)\n",
    "activation1 = Activation_ReLU()\n",
    "\n",
    "# Forward pass\n",
    "layer1.forward(X)\n",
    "activation1.forward(layer1.output)\n",
    "\n",
    "layer2 = Layer_Dense(5, 3)\n",
    "activation2 = Activation_Softmax()\n",
    "\n",
    "layer2.forward(activation1.output)\n",
    "activation2.forward(layer2.output)\n",
    "print(activation2.output[:5])\n",
    "# Loss\n",
    "loss_function = Loss_Categorical_Cross_entropy()\n",
    "loss = loss_function.calculate(activation2.output, y)\n",
    "\n",
    "print(loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "735156e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
